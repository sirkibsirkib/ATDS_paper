This section explores the weaknesses of the languages from Section~\ref{how}. We discuss how these weaknesses are currently mitigated and how they might be improved further in the future.


\textbf{Chapel}'s layered approach to the granularity of code, as discussed in \ref{how:clarity}, allows the programmer to gloss over details when a high-level approach is sufficient. Unfortunately, Chapel's high-level `global view' has been found to under-perform when compared to the same algorithm implemented in the lower, `local view'. This is a result of the compiler's shortcoming, and perhaps a mismatch between the expectations of the programmer and the actions of the compiler. With refinement, development of the Chapel language hopes to incrementally close this performance gap~\cite{chapel,globalViewChaphel}.


Coordination languages have shown immense promise, with \textbf{Linda} and \textbf{Reo} both showcasing all of our selected requirements. \textbf{Linda} has been shown to out-perform a message-passing competitor significantly, particularly for larger-scale systems~\cite{LindaVSMessage}; this is explored further in Section~\ref{sec:how:performance}. However, these findings are out of date, while comparisons to more modern competitors are scarce. \textbf{Reo} is a newer language, and it benefits from more up-to-date performance measurements to relevant technologies (such as C with MPI)~\cite{proper}. Overall, it demonstrates competitive performance, as described in Section~\ref{sec:how:performance}. Unfortunately, an experiment found Reo to be between 10\% and 40\% slower in 25\% of cases, suggesting that performance is not guaranteed to consistently exceed that of imperative languages~\cite{proper}. Concerns have also been raised about the \textbf{reliability} of Reo, as the exploration of their formal correctness has not yet been thoroughly proven. This is the case for many languages while still in early development. Owing to its verifiable nature, we believe Reo will overcome this limitation given time to develop.

The ownership system present in \textbf{Rust} and \textbf{Impala} does not incur any run-time performance penalty, as explored in 
\ref{sec:how:performance}. However, memory safety necessitates that the programmer specifies the \textit{lifetimes} of variables in scope in relation to one another~\cite{rustSystem}. In practice, this means code is sometimes peppered by lifetime variables, which leads to a loss of \textbf{clarity} at first glance. The Rust developers have considered this, and have added \textit{lifetime elision rules} that allow the compiler to implicitly infer omitted lifetimes in most cases~\cite{rustlang}. Programmers also experience `fighting with the compiler', attempting to express something not inherently memory-safe (as with the \textit{hogwild} example in Section~\ref{how:clarity}). This can be considered a lack of \textbf{expressiveness} in the language. Fortunately, Rust's \textit{unsafe} language subset is intended for precisely this purpose, ensuring such restrictions in expressivity are more like speed-bumps, and less like road-blocks.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\label{sec:tradeoff:general}
A more general problem when programming with high-level tools that abstract away from an underlying low-level implementation, it is desired that the resulting implementation is less complex than if the same task would be solved in this underlying language. This closely relates to the \textit{complexity gap}, stating that there is an arbitrarily large gap between two complexity classes and discussing the bound relating the two~\cite{complexityGap}. In some cases one could argue that a task could be more trivially solved in a low-level language such as C, rather than using a more abstract language or tool, compiling down to a similar code base. Acknowledging that this in some cases can be true~\cite{chapel}; we should not focus on these individual cases but on the bigger picture. In, for example, a declarative system, one can more effectively maintain the separation of semantics and implementation. This implies less implementation complexity for future reference or when adding extra functionality. Also, systems tend to grow in complexity as functionality is added~\cite{coordination}. With this, the complexity gap between the two quickly diminishes, especially when a system scales in a more complex setting, such as parallel and distributed computing. See Section~\ref{how} for more insight into why abstracting away from low-level language is desirable.
